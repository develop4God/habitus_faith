{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HABITUS FAITH - ML Training Pipeline (Optimized)\n",
        "\n",
        "Improved version with better archetype separation and model architecture\n",
        "\n",
        "## Expected outputs\n",
        "- predictor.tflite\n",
        "- scaler_params.json\n",
        "- feature_config.json\n",
        "\n",
        "## Estimated time: 5-10 minutes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_synthetic_training_data(n_records=5000):\n",
        "    \"\"\"Generate synthetic data with clear archetype separation\"\"\"\n",
        "    np.random.seed(42)\n",
        "    records = []\n",
        "    \n",
        "    archetypes = {\n",
        "        'excellent_morning': {\n",
        "            'weight': 0.20,\n",
        "            'hour_range': (6, 9),\n",
        "            'hour_std': 0.5,\n",
        "            'preferred_days': [1, 2, 3, 4, 5],\n",
        "            'streak_range': (30, 90),\n",
        "            'failure_range': (0, 1),\n",
        "            'reminder_adherence': 0.95,\n",
        "            'abandonment_rate': 0.02\n",
        "        },\n",
        "        'consistent_afternoon': {\n",
        "            'weight': 0.20,\n",
        "            'hour_range': (13, 16),\n",
        "            'hour_std': 1.0,\n",
        "            'preferred_days': [1, 2, 3, 4, 5, 6, 7],\n",
        "            'streak_range': (15, 45),\n",
        "            'failure_range': (1, 2),\n",
        "            'reminder_adherence': 0.75,\n",
        "            'abandonment_rate': 0.15\n",
        "        },\n",
        "        'moderate_evening': {\n",
        "            'weight': 0.20,\n",
        "            'hour_range': (18, 21),\n",
        "            'hour_std': 1.5,\n",
        "            'preferred_days': [1, 2, 3, 4, 5, 6, 7],\n",
        "            'streak_range': (8, 25),\n",
        "            'failure_range': (2, 4),\n",
        "            'reminder_adherence': 0.55,\n",
        "            'abandonment_rate': 0.40\n",
        "        },\n",
        "        'struggling_night': {\n",
        "            'weight': 0.20,\n",
        "            'hour_range': (20, 23),\n",
        "            'hour_std': 1.5,\n",
        "            'preferred_days': [5, 6, 7],\n",
        "            'streak_range': (1, 10),\n",
        "            'failure_range': (4, 6),\n",
        "            'reminder_adherence': 0.30,\n",
        "            'abandonment_rate': 0.75\n",
        "        },\n",
        "        'inconsistent_weekend': {\n",
        "            'weight': 0.20,\n",
        "            'hour_range': (8, 14),\n",
        "            'hour_std': 3.0,\n",
        "            'preferred_days': [6, 7],\n",
        "            'streak_range': (2, 12),\n",
        "            'failure_range': (3, 5),\n",
        "            'reminder_adherence': 0.35,\n",
        "            'abandonment_rate': 0.65\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    for i in range(n_records):\n",
        "        archetype_name = np.random.choice(\n",
        "            list(archetypes.keys()),\n",
        "            p=[arch['weight'] for arch in archetypes.values()]\n",
        "        )\n",
        "        archetype = archetypes[archetype_name]\n",
        "        \n",
        "        hour_mean = np.mean(archetype['hour_range'])\n",
        "        hour = np.clip(np.random.normal(hour_mean, archetype['hour_std']), 0, 23)\n",
        "        \n",
        "        day = np.random.choice(archetype['preferred_days'])\n",
        "        streak = np.random.randint(archetype['streak_range'][0], archetype['streak_range'][1] + 1)\n",
        "        failures = np.random.randint(archetype['failure_range'][0], archetype['failure_range'][1] + 1)\n",
        "        \n",
        "        if np.random.random() < archetype['reminder_adherence']:\n",
        "            hours_from_reminder = np.random.uniform(0, 2)\n",
        "        else:\n",
        "            hours_from_reminder = np.random.uniform(2, 12)\n",
        "        \n",
        "        base_risk = archetype['abandonment_rate']\n",
        "        abandoned = 1 if np.random.random() < base_risk else 0\n",
        "        \n",
        "        records.append({\n",
        "            'hourOfDay': hour,\n",
        "            'dayOfWeek': day,\n",
        "            'streakAtTime': streak,\n",
        "            'failuresLast7Days': failures,\n",
        "            'hoursFromReminder': hours_from_reminder,\n",
        "            'abandoned': abandoned\n",
        "        })\n",
        "    \n",
        "    df = pd.DataFrame(records)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Generating 5000 synthetic training records...')\n",
        "df = generate_synthetic_training_data(5000)\n",
        "print(f'Generated {len(df)} records')\n",
        "print(f'\\nClass distribution:')\n",
        "print(f\"   - Completed (0): {(~df['abandoned'].astype(bool)).sum()} ({(~df['abandoned'].astype(bool)).sum()/len(df)*100:.1f}%)\")\n",
        "print(f\"   - Abandoned (1): {df['abandoned'].sum()} ({df['abandoned'].sum()/len(df)*100:.1f}%)\")\n",
        "print(f'\\nFirst 5 records:')\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('\\nFeature Statistics:')\n",
        "print(df.describe())\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "\n",
        "axes[0, 0].hist([df[df['abandoned']==0]['hourOfDay'], df[df['abandoned']==1]['hourOfDay']], \n",
        "                bins=24, label=['Completed', 'Abandoned'], alpha=0.7)\n",
        "axes[0, 0].set_title('Completion Hour Distribution')\n",
        "axes[0, 0].set_xlabel('Hour of Day')\n",
        "axes[0, 0].legend()\n",
        "\n",
        "axes[0, 1].hist([df[df['abandoned']==0]['dayOfWeek'], df[df['abandoned']==1]['dayOfWeek']], \n",
        "                bins=7, label=['Completed', 'Abandoned'], alpha=0.7)\n",
        "axes[0, 1].set_title('Day of Week Distribution')\n",
        "axes[0, 1].set_xlabel('Day (1=Mon, 7=Sun)')\n",
        "axes[0, 1].legend()\n",
        "\n",
        "axes[0, 2].hist([df[df['abandoned']==0]['streakAtTime'], df[df['abandoned']==1]['streakAtTime']], \n",
        "                bins=20, label=['Completed', 'Abandoned'], alpha=0.7)\n",
        "axes[0, 2].set_title('Streak Distribution')\n",
        "axes[0, 2].set_xlabel('Streak Length')\n",
        "axes[0, 2].legend()\n",
        "\n",
        "axes[1, 0].hist([df[df['abandoned']==0]['failuresLast7Days'], df[df['abandoned']==1]['failuresLast7Days']], \n",
        "                bins=8, label=['Completed', 'Abandoned'], alpha=0.7)\n",
        "axes[1, 0].set_title('Failures Last 7 Days')\n",
        "axes[1, 0].set_xlabel('Number of Failures')\n",
        "axes[1, 0].legend()\n",
        "\n",
        "axes[1, 1].hist([df[df['abandoned']==0]['hoursFromReminder'], df[df['abandoned']==1]['hoursFromReminder']], \n",
        "                bins=12, label=['Completed', 'Abandoned'], alpha=0.7)\n",
        "axes[1, 1].set_title('Hours From Reminder')\n",
        "axes[1, 1].set_xlabel('Hours')\n",
        "axes[1, 1].legend()\n",
        "\n",
        "sns.heatmap(df.corr(), annot=True, fmt='.2f', cmap='coolwarm', ax=axes[1, 2])\n",
        "axes[1, 2].set_title('Feature Correlation')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('='*60)\n",
        "print('TRAINING IMPROVED MODEL')\n",
        "print('='*60)\n",
        "\n",
        "feature_cols = ['hourOfDay', 'dayOfWeek', 'streakAtTime', 'failuresLast7Days', 'hoursFromReminder']\n",
        "X = df[feature_cols].values\n",
        "y = df['abandoned'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f'\\nData split:')\n",
        "print(f'   Training: {len(X_train)} samples')\n",
        "print(f'   Testing: {len(X_test)} samples')\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(f'\\nBuilding Neural Network with Dropout...')\n",
        "keras_model = Sequential([\n",
        "    Dense(32, activation='relu', input_shape=(5,)),\n",
        "    Dropout(0.3),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "keras_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
        ")\n",
        "\n",
        "keras_model.summary()\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=15,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(f'\\nTraining...')\n",
        "history = keras_model.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "test_loss, test_accuracy, test_auc = keras_model.evaluate(X_test_scaled, y_test, verbose=0)\n",
        "print(f'\\n{\"=\"*60}')\n",
        "print(f'Test Accuracy: {test_accuracy:.2%}')\n",
        "print(f'Test AUC: {test_auc:.4f}')\n",
        "print(f'Test Loss: {test_loss:.4f}')\n",
        "print(f'{\"=\"*60}')\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_scenarios = [\n",
        "    ([7.0, 1, 45, 0, 1], \"Excellent morning (low risk)\"),\n",
        "    ([14.0, 3, 20, 1, 2], \"Consistent afternoon (low risk)\"),\n",
        "    ([19.0, 5, 10, 3, 4], \"Moderate evening (medium risk)\"),\n",
        "    ([21.0, 6, 5, 5, 8], \"Struggling night (high risk)\"),\n",
        "    ([11.0, 7, 3, 4, 10], \"Inconsistent weekend (high risk)\")\n",
        "]\n",
        "\n",
        "print(f'\\n{\"=\"*60}')\n",
        "print('TEST PREDICTIONS (Keras Model):')\n",
        "print(f'{\"=\"*60}')\n",
        "for features, desc in test_scenarios:\n",
        "    features_scaled = scaler.transform([features])\n",
        "    pred = keras_model.predict(features_scaled, verbose=0)[0][0]\n",
        "    print(f'{desc:40} â†’ {pred:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('\\n' + '='*60)\n",
        "print('EXPORTING TO TFLITE')\n",
        "print('='*60)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('predictor.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "tflite_size_kb = len(tflite_model) / 1024\n",
        "print(f'âœ… TFLite model saved: {tflite_size_kb:.2f} KB')\n",
        "\n",
        "scaler_params = {\n",
        "    'mean': scaler.mean_.tolist(),\n",
        "    'scale': scaler.scale_.tolist()\n",
        "}\n",
        "\n",
        "with open('scaler_params.json', 'w') as f:\n",
        "    json.dump(scaler_params, f, indent=2)\n",
        "\n",
        "print(f'âœ… Scaler params saved')\n",
        "\n",
        "feature_config = {\n",
        "    'features': feature_cols\n",
        "}\n",
        "\n",
        "with open('feature_config.json', 'w') as f:\n",
        "    json.dump(feature_config, f, indent=2)\n",
        "\n",
        "print(f'âœ… Feature config saved')\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "print(f'\\nTFLite Input shape: {input_details[0][\"shape\"]}')\n",
        "print(f'TFLite Output shape: {output_details[0][\"shape\"]}')\n",
        "\n",
        "print(f'\\n{\"=\"*60}')\n",
        "print('TFLITE VERIFICATION:')\n",
        "print(f'{\"=\"*60}')\n",
        "for features, desc in test_scenarios:\n",
        "    features_scaled = scaler.transform([features]).astype(np.float32)\n",
        "    interpreter.set_tensor(input_details[0]['index'], features_scaled)\n",
        "    interpreter.invoke()\n",
        "    output = interpreter.get_tensor(output_details[0]['index'])[0][0]\n",
        "    print(f'{desc:40} â†’ {output:.4f}')\n",
        "\n",
        "print(f'\\n{\"=\"*60}')\n",
        "print('EXPORT COMPLETE!')\n",
        "print(f'{\"=\"*60}')\n",
        "print(f'\\nðŸ“¦ Output files:')\n",
        "print(f'   1. predictor.tflite ({tflite_size_kb:.2f} KB)')\n",
        "print(f'   2. scaler_params.json')\n",
        "print(f'   3. feature_config.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "print('\\nDownloading files...')\n",
        "files.download('predictor.tflite')\n",
        "files.download('scaler_params.json')\n",
        "files.download('feature_config.json')\n",
        "print('\\nâœ… Downloads initiated! Check your browser download folder.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Next Steps\n",
        "\n",
        "## 1. Copy files to Flutter project\n",
        "\n",
        "```\n",
        "assets/ml_models/\n",
        "â”œâ”€â”€ predictor.tflite\n",
        "â”œâ”€â”€ scaler_params.json\n",
        "â””â”€â”€ feature_config.json\n",
        "```\n",
        "\n",
        "## 2. Run integration test\n",
        "\n",
        "```bash\n",
        "flutter test integration_test/ml/ml_prediction_flow_test.dart -d YOUR_DEVICE_ID\n",
        "```\n",
        "\n",
        "## 3. Expected test results\n",
        "\n",
        "- Low-risk scenarios: 0.05-0.20\n",
        "- Medium-risk scenarios: 0.35-0.55\n",
        "- High-risk scenarios: 0.70-0.85\n",
        "\n",
        "## 4. Future retraining\n",
        "\n",
        "When you have â‰¥500 real user completions in Firestore, export data and retrain for better accuracy."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}